{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFake_Image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suneel87/Deep-Fake-Image-Detection/blob/main/DeepFake_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26_qT2-7YPNR",
        "outputId": "9d3e8c21-2855-46ff-d44c-48388571cb7b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tx2r8YQ_QS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e441661-d401-43da-e1ca-07fd6d0c8c27"
      },
      "source": [
        "pip install streamlit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.2.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.24)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.7.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.3)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.1)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.18.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.6)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.5)\n",
            "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (6.6.0)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.1.1)\n",
            "Requirement already satisfied: importlib-metadata<5 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.2)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.3)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: argcomplete>=1.12.3 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.12.3)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.30.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.24)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.9.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.12.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5naTQ8yy5UU"
      },
      "source": [
        "### **Import Necessary Modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njb7fTuzYmc0"
      },
      "source": [
        "from itertools import permutations, product\n",
        "from random import sample, choice, shuffle\n",
        "from glob import glob\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps    \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import streamlit as st"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPTCS58ezAzC"
      },
      "source": [
        "### **Functions Used**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-32B_u_pZrbs"
      },
      "source": [
        "'''\n",
        "This functions computes the Contrastive loss for a CFFN\n",
        "\n",
        "Input: Label(y)(0 or 1), Feature Vectors for a pair of images(fx1,fx2)\n",
        "Output: The value of Contrastive loss\n",
        "Return Type: PyTorch Tensor\n",
        "'''\n",
        "def ContrastiveLoss(y,fx1,fx2):\n",
        "  m=2\n",
        "  E=torch.pow((fx1-fx2),2)\n",
        "  mat_max = np.maximum(np.zeros((y.shape[0], 128)), torch.pow((m-E),2).detach().cpu().numpy())\n",
        "  torch_loss = 0.5*(y.detach().cpu().numpy()*torch.pow(E,2).detach().cpu().numpy().T) + (1-y.detach().cpu().numpy())*mat_max.T\n",
        "  return torch.tensor(torch.sum(torch.tensor(torch_loss.T)), requires_grad=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSsXcRYazZoM"
      },
      "source": [
        "'''\n",
        "This functions plots multiple images in one grid\n",
        "\n",
        "Input: A grid of images made using torch.utils\n",
        "Output: The plot (matplotlib) for these images in one grid\n",
        "'''\n",
        "def imshow(img,text=None,should_save=False):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IAHXgkezbpy"
      },
      "source": [
        "'''\n",
        "This functions plots the loss for that particular iteration in an epoch\n",
        "\n",
        "Input: Iteration Number (iteration) and the Loss (loss)\n",
        "Output: The matplotlib plot for the loss\n",
        "'''\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jifCutAg1mxw"
      },
      "source": [
        "'''\n",
        "This functions predicts the state of a given image\n",
        "\n",
        "Input: The image (image)\n",
        "Output: The value of the state of the image (0 for fake and 1 for real)\n",
        "Return Type: Integer\n",
        "'''\n",
        "def predict_image(image):\n",
        "\n",
        "    net = SiameseNetwork(models.resnet50(pretrained=True),1000).cuda()\n",
        "    net2 = NeuralNet().cuda()\n",
        "\n",
        "    net.load_state_dict(torch.load(\"net.pth\"))\n",
        "    net2.load_state_dict(torch.load(\"net2.pth\"))\n",
        "\n",
        "    net.eval()\n",
        "    net2.eval()\n",
        "    test_transforms = transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor()])\n",
        "    img=Image.open(image)\n",
        "    image_tensor = test_transforms(img).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input = Variable(image_tensor)\n",
        "    input = input.cuda()\n",
        "    out1=net([input])\n",
        "    output = net2(out1[0])\n",
        "    print(output.data.cpu().numpy())\n",
        "    index = output.data.cpu().numpy().argmax()\n",
        "    \n",
        "    return index"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VICbCScXzFuK"
      },
      "source": [
        "### **Reading the images and pairing them**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atyPSYVkYvMc"
      },
      "source": [
        "fake = glob(\"/content/drive/My Drive/faces/fake/*\")\n",
        "real = glob(\"/content/drive/My Drive/faces/real/*\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxzc1BpdZepn"
      },
      "source": [
        "fake_ = [x.split(\"/\")[-1] for x in fake]\n",
        "real_ = [x.split(\"/\")[-1] for x in real]\n",
        "\n",
        "fake_ = [\"fake_\" + x for x in fake_]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td6l60uaZvvU",
        "outputId": "06548051-cfe2-40bb-8769-db58ca45f61e"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "pairs_distinct = list(product(real_,fake_))\n",
        "\n",
        "pairs_real = list(product(real_,real_))\n",
        "\n",
        "pairs_fake = list(product(fake_,fake_))\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f'Time Taken: {timedelta(seconds=(end - start))}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken: 0:00:00.325161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhbK4S-0CRs5",
        "outputId": "9610cea8-f902-410c-f73e-ca2949f40f37"
      },
      "source": [
        "len(pairs_distinct) + len(pairs_fake) + len(pairs_real)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3127921"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RadXNKYraD0V"
      },
      "source": [
        "pairs = pairs_distinct + pairs_real + pairs_fake\n",
        "pairs = sample(pairs, len(pairs))\n",
        "pairs = list(set(pairs))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5PJGEAfaG_S",
        "outputId": "ae441c84-df07-44e9-bbb2-55d4d381b6f0"
      },
      "source": [
        "ord('f'), ord('r')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GGJ9WFHaIi5",
        "outputId": "2c41cf6e-1cd5-4674-cb3a-0fda24f117d1"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "label_dict = {}\n",
        "for idx, pair in enumerate(pairs):\n",
        "    l1, l2 = pair[0].split(\"_\")[0][0], pair[1].split(\"_\")[0][0]\n",
        "    \n",
        "    l_sum = ord(l1) + ord(l2)\n",
        "    \n",
        "    if l_sum == 204:\n",
        "        label = 1 #impostor pair\n",
        "    elif l_sum == 216:\n",
        "        label = 0\n",
        "    elif l_sum == 228:\n",
        "        label = 1 # real pair\n",
        "    \n",
        "    label_dict[idx] = label\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f'Time Taken: {timedelta(seconds=(end - start))}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken: 0:00:04.738180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7his_jz1zgIi"
      },
      "source": [
        "### **Forming a Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEzLD_VFaPUn"
      },
      "source": [
        "BATCH_SIZE=64\n",
        "NUMBER_EPOCHS=30\n",
        "IMG_SIZE=100"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "UWnu-SRu0GQr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_per = .70\n",
        "test_per = .15\n",
        "val_per = .15\n",
        "total_len = len(pairs)\n",
        "\n",
        "a, b = sklearn.model_selection.train_test_split(pairs, train_size=train_per, test_size=test_per + val_per)\n",
        "b, c = sklearn.model_selection.train_test_split(b, train_size=test_per, test_size=val_per)"
      ],
      "metadata": {
        "id": "HzVY_HU4x2wj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kPSvT7PkJXQ",
        "outputId": "0449080b-af8b-49b0-b0fd-48dbfd75d77c"
      },
      "source": [
        "len(a), len(b), len(c)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2189544, 140756, 140757)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekbS8d16aNEc"
      },
      "source": [
        "class DFDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, root_dir, real_dir, fake_dir, pairs, lab_dict, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.real_dir = real_dir\n",
        "        self.fake_dir = fake_dir\n",
        "        self.transform = transform\n",
        "        self.pairs = pairs\n",
        "        self.lab_dict = lab_dict\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.pairs[idx]\n",
        "        class_labels = []\n",
        "        \n",
        "        if pair[0].split(\"_\")[0] == \"real\":\n",
        "            img1 = Image.open(f'{self.root_dir}/{self.real_dir}/{pair[0]}')\n",
        "            class_labels.append(1)\n",
        "            \n",
        "        elif pair[0].split(\"_\")[0] == \"fake\":\n",
        "            path_ = pair[0].replace('fake_', '')\n",
        "            img1 = Image.open(f'{self.root_dir}/{self.fake_dir}/{path_}')\n",
        "            class_labels.append(0)\n",
        "            \n",
        "        if pair[1].split(\"_\")[0] == \"real\":\n",
        "            img2 = Image.open(f'{self.root_dir}/{self.real_dir}/{pair[1]}')\n",
        "            class_labels.append(1)\n",
        "            \n",
        "        elif pair[1].split(\"_\")[0] == \"fake\":\n",
        "            path_ = pair[1].replace('fake_', '')\n",
        "            img2 = Image.open(f'{self.root_dir}/{self.fake_dir}/{path_}')\n",
        "            class_labels.append(0)\n",
        "            \n",
        "        if self.transform is not None:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "            \n",
        "        \n",
        "        label = self.lab_dict[idx]\n",
        "        \n",
        "        return img1, img2, label, class_labels\n",
        "        "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAAmK6JZaQ-D"
      },
      "source": [
        "trainset = DFDataset('/content/drive/My Drive/faces', 'real', 'fake', sample(list(a), 10000), label_dict, \n",
        "                                                             transform=transforms.Compose([transforms.Resize((100,100)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ]))\n",
        "\n",
        "trainloader = DataLoader(trainset,\n",
        "                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.\n",
        "                        batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "valset = DFDataset('/content/drive/My Drive/faces', 'real', 'fake', sample(list(c), 10000), label_dict, \n",
        "                                                             transform=transforms.Compose([transforms.Resize((100,100)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ]))\n",
        "\n",
        "valloader = DataLoader(valset,\n",
        "                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.\n",
        "                        batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "l03d7g2Zahd5",
        "outputId": "70dfd379-f1b2-413b-e97f-137bb711554c"
      },
      "source": [
        "vis_dataloader = DataLoader(trainset,\n",
        "                        shuffle=True,\n",
        "                        batch_size=8)\n",
        "dataiter = iter(vis_dataloader)\n",
        "\n",
        "\n",
        "example_batch = next(dataiter)\n",
        "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9N5nl5E0RvT"
      },
      "source": [
        "### **Building a CFFN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9-7De2VbCp7"
      },
      "source": [
        "class SiameseNetwork(nn.Module):# A simple implementation of siamese network\n",
        "    def __init__(self,model,n):#Parameters: The name of the model used and the size\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn1 = model\n",
        "        self.fc1 = nn.Linear(n, 500)\n",
        "        self.fc2 = nn.Linear(500, 500)\n",
        "        self.fc3 = nn.Linear(500, 128)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        results = []\n",
        "\n",
        "        for input in inputs:\n",
        "            output = self.cnn1(input)\n",
        "            output = output.view(output.size()[0], -1)\n",
        "            output = F.relu(self.fc1(output))\n",
        "            output = F.relu(self.fc2(output))\n",
        "            output = self.fc3(output)\n",
        "\n",
        "            results.append(output)\n",
        "\n",
        "        return results"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-jnl2-wbErT",
        "outputId": "f160b9b4-5ec4-45d6-a0e2-a1cbf22091b5"
      },
      "source": [
        "# custom_cnn =  nn.Sequential(\n",
        "#             nn.ReflectionPad2d(1),\n",
        "#             nn.Conv2d(3, BATCH_SIZE, kernel_size=3),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.BatchNorm2d(BATCH_SIZE),\n",
        "#             nn.Dropout2d(p=.2),\n",
        "            \n",
        "#             nn.ReflectionPad2d(1),\n",
        "#             nn.Conv2d(BATCH_SIZE, BATCH_SIZE, kernel_size=3),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.BatchNorm2d(BATCH_SIZE),\n",
        "#             nn.Dropout2d(p=.2),\n",
        "\n",
        "#             nn.ReflectionPad2d(1),\n",
        "#             nn.Conv2d(BATCH_SIZE, 32, kernel_size=3),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.Dropout2d(p=.2),\n",
        "#         )\n",
        "\n",
        "# custom_cnn_n = 32*100*100\n",
        "\n",
        "#models.resnet50(pretrained=True)\n",
        "\n",
        "#models.alexnet(pretrained=True)\n",
        "\n",
        "#models.densenet(pretrained=True)\n",
        "\n",
        "#models.vgg16(pretrained=True)\n",
        "\n",
        "#models.resnet50(pretrained=True)\n",
        "\n",
        "#models.googlenet(pretrained=True)\n",
        "\n",
        "net = SiameseNetwork(models.resnet50(pretrained=True),1000).cuda()\n",
        "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "counter = []\n",
        "loss_history = [] \n",
        "iteration_number= 0\n",
        "\n",
        "for epoch in range(0,NUMBER_EPOCHS):\n",
        "    print(\"Epoch：\", epoch, \" start.\")\n",
        "    for i, data in enumerate(trainloader,0):\n",
        "        img0, img1 , labels, _ = data\n",
        "        img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()#move to GPU\n",
        "        #print(\"epoch：\", epoch, \"No.\" , i, \"th inputs\", img0.data.size(), \"labels\", labels.data.size())\n",
        "        optimizer.zero_grad()#clear the calculated grad in previous batch\n",
        "        outputs = net([img0,img1])\n",
        "        loss = ContrastiveLoss(labels, outputs[0], outputs[1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"Iteration number {}\\n Current loss {}\\n\".format(i,loss.item()))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch： 0  start.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 11305.914778864737\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 13285.294618016957\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 11289.981258231297\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 8342.420593649507\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 8840.501541405167\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 8821.536519070993\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 10801.261347586644\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 9845.174391387523\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 11332.21165522478\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 12278.537449295465\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 9331.65668631564\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 12278.87478676081\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 13765.994647135498\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 10336.472500753174\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 11780.859339066545\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 10761.186220159794\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 6861.41224927881\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 10333.628269331506\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 11829.501958482555\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 11753.400002617247\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 7872.1512365622\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 9321.272672894986\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 12735.441032055725\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 11847.099641431227\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 9333.993958986433\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 9820.224825523996\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 10288.856074794843\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 10791.846862031143\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 10286.492895305237\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 8364.875770810093\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 12209.193351165299\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 10304.847437806067\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 11286.70192669032\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 7851.942100123755\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 10755.551355412037\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 9326.797306945928\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 10323.665235149145\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 8837.217931902935\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 7824.374680635637\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 7859.395452334387\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 12296.34281356549\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 10802.067716236576\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 13775.76786104645\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 11284.196596938888\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 11333.651935314592\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 10294.359086050776\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 10818.76881610879\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 9832.345261254966\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 11258.939477336979\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 10786.07553911454\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 10803.081961262667\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 7903.52573833488\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 8341.906623244613\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 12785.461495432286\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 12292.112717159163\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 9834.139476357752\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 8855.555929172708\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 10793.718045460908\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 11273.732411744484\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 9808.625370823356\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 10805.364988067624\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 12271.257127011299\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 12261.18153808224\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 11281.940594908381\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 10314.673905629385\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 14257.002780159437\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 6877.970260042128\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 8354.395177863778\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 11263.63603266925\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 7884.8228268001185\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 8398.493615354855\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 9337.429343909476\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 11270.280118125667\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 10303.02311389083\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 7348.310670835718\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 8878.02199007072\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 10288.97582469725\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 12281.880196910546\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 11331.711156044254\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 6366.614069080306\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 7817.57135948225\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 5931.642837211188\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 13770.48155795548\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 8313.8780860181\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 6883.083041719298\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 8868.345562249204\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 11269.993182828239\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 14737.134766010173\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 11280.328474613267\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 12263.392904359347\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 10782.544487905065\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 8856.630268915831\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 2473.474485142682\n",
            "\n",
            "Epoch： 20  start.\n",
            "Iteration number 0\n",
            " Current loss 11288.688413551477\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 12739.278167765693\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 10832.187407217509\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 8322.534637282724\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 9330.953506162163\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 11811.83419827047\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 9831.2128040272\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 7375.09022287593\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 11292.77151252535\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 10823.174280921381\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 10365.480508087456\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 11286.245682227029\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 10268.623098194774\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 10327.418732963544\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 10803.248831252224\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 10808.27179282142\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 9810.737478435633\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 10329.98115375203\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 9329.129510289222\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 10313.535490242608\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 14782.252964858915\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 8831.968080736526\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 10320.0947840162\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 12346.273710308828\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 10342.762230034816\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 9827.509013233326\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 10330.993790772409\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 10295.462317664267\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 7882.745657765132\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 8829.820338287383\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 8352.37516550173\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 9816.508235276488\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 11264.787663737712\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 8357.570953904868\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 9809.833889917612\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 9842.93790339786\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 15224.106661288042\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 9368.194116328767\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 13279.829431670883\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 10866.99419154504\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 10805.44670669661\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 10868.02539219419\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 8364.405545341386\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 8365.499580578098\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 12283.58786473864\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 11813.825287117314\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 13243.534122842268\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 12781.003571804864\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 11233.100579267446\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 8855.392237429365\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 9848.212536860796\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 10291.826246819055\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 9366.636738093546\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 8372.984743084275\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 9347.217346152855\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 10313.511313062118\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 10852.87170985547\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 11295.834933616716\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 13304.276932784089\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 8356.919756798254\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 8872.506094003316\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 9785.74268573579\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 13724.898642599028\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 11763.851802690815\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 9320.1712194032\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 9850.301300620755\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 10813.132691121096\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 11285.67662260736\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 11813.384734505602\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 14240.166823865577\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 12256.072965052146\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 12278.740509596058\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 12805.850267732483\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 9761.357975871328\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 7876.32480326593\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 9333.149241631965\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 8362.690522975403\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 7414.810855657363\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 14234.294756441437\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 9314.640410204063\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 10330.265123528625\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 11276.347127823308\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 11340.210713381803\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 10326.123517873952\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 9815.81952963871\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 11298.404000993887\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 11302.824486295971\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 10795.079495129849\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 10799.28419277503\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 11270.811891986885\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 11271.320455037785\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 10806.876556942407\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 9349.746987166884\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 8822.70818924403\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 11835.495915048588\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 10824.702063771398\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 8816.251228247249\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 7367.133410878394\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 10377.993978678807\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 6855.147607017507\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 10311.119186719987\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 9790.889642351383\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 9850.614814726307\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 7350.507212188362\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 7872.894623562148\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 7843.902191468402\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 10821.308406564543\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 8825.634254185252\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 6412.057125046044\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 12242.153947371993\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 11798.610271768957\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 9307.481234145675\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 9345.110774234392\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 11331.57115877594\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 10316.40460892152\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 10820.053064469259\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 8374.700256084041\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 9869.119856134255\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 13741.186517239314\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 9803.849012541523\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 7847.266804279268\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 8801.804281846604\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 12733.063035587147\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 11301.422860542643\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 10783.53223609198\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 10265.772378530193\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 11317.605764610684\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 9884.049996721582\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 9301.828134664975\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 8840.623335552174\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 11299.383939330395\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 11329.758128101217\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 9315.337364060939\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 10778.17067503073\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 9820.221126746612\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 9827.803263504095\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 7347.1338722398195\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 9781.520403942995\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 9337.658808680811\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 9839.42126675758\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 9801.880602246783\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 13280.518647783654\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 10786.568416129514\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 9822.89911635077\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 11268.870878846232\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 13250.450921870077\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 10313.704235838064\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 11768.094373644411\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 8865.110980310239\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 5883.604436823279\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 7394.075452695982\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 7846.777839326178\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 9316.607703634478\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 9836.196314857809\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 9310.88510200844\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 11330.073272759233\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 3929.8905018713012\n",
            "\n",
            "Epoch： 21  start.\n",
            "Iteration number 0\n",
            " Current loss 10312.497753067099\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 12305.811321909576\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 12780.518312546952\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 11329.953024662836\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 11279.568666896968\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 11822.922633201333\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 11814.034021182199\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 11322.104928864093\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 9325.51206716098\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 10274.776077299972\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 8831.452036778363\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 11297.868495938092\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 11259.248068641344\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 7376.899677121665\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 11264.457647225165\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 13702.896389173777\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 8848.927952805298\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 13273.461044320302\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 8871.711505025742\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 13795.759997449159\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 10347.175490307269\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 13694.011780096384\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 11763.676851779239\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 11197.766108928163\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 10321.826066179825\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 8810.43425104646\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 14247.453240929832\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 11295.850557728696\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 14729.265862945016\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 13296.402707422481\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 9837.60048680175\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 8859.322358436857\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 6873.581849467202\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 8835.108624516997\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 7870.14565547006\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 11290.34151594376\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 9806.703320476834\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 8322.395729685068\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 11804.063000279473\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 9849.381289803736\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 12298.252427022337\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 11797.507664996325\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 13262.570353072831\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 7872.0555853599835\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 9851.42576354421\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 9863.222465443805\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 11323.767199301954\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 10243.352107625029\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 11288.371083571517\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 8362.39214598424\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 10806.372974593038\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 11777.674196608788\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 11308.008874445795\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 11779.044734852818\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 9328.178239081692\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 11807.374094391194\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 10771.80156451691\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 10333.547579311282\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 11785.822019215106\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 8372.571493817239\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 10842.230653535345\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 13273.731478474238\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 9815.165892868146\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 11328.733373684303\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 10795.60954915568\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 8924.99624597469\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 8803.108384664003\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 10808.028308057877\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 10342.054178658724\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 9334.800668685166\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 13251.268683136504\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 9845.809917984247\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 11256.577673071453\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 12714.062237657705\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 9329.18844751859\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 9343.686848219877\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 12756.481097495689\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 10306.992962484186\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 10310.204286738752\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 8361.252481430056\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 10771.015769949929\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 10784.282090734043\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 6933.276745066389\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 9850.62148352203\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 5894.03901989543\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 9348.50082293017\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 6875.5286526500695\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 5411.206819371505\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 10832.281613196978\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 10357.953824480406\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 12281.799597469097\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 12229.508201465916\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 6388.215467494582\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 10798.53097523059\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 9807.694285255558\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 8394.49468066267\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 11726.945271375553\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 11295.013808312891\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 8858.796491579706\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 7867.87356267553\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 10811.418442442717\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 10841.402344434799\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 14271.071009867903\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 10325.08424806206\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 9807.670813138096\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 9821.50962532586\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 8831.951953875796\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 9839.589030301402\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 7352.224889019202\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 9311.331207458277\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 7861.828730450836\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 10773.820555576634\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 14791.434494222374\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 11247.431846169282\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 8355.72419058984\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 8865.83672213448\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 10815.367003013063\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 10354.670720211088\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 9789.095985402064\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 5911.540722025964\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 8836.368242402736\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 8398.96464838158\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 9308.842621362806\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 7877.202564430058\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 11314.921819264953\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 9836.839981489822\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 10767.131485156866\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 9342.757901155266\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 8821.115382662312\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 11324.88991700407\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 9347.007000567692\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 8377.540549199442\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 12262.688752490789\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 9832.365097545835\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 9793.641987526644\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 12263.414669121914\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 7876.19144435082\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 12804.111146882024\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 11786.870273687862\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 8842.63669864887\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 10835.578220730584\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 5934.08937333822\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 11813.935364997638\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 10293.197376506547\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 7856.462172715112\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 7799.679341903973\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 10327.518956592941\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 9832.65959966341\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 9822.769473762039\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 9328.66449365605\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 13252.821294662182\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 11293.535244316074\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 8853.543016853462\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 9853.896001328543\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 8346.157998249066\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 13225.923390975706\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 2476.7431039142925\n",
            "\n",
            "Epoch： 22  start.\n",
            "Iteration number 0\n",
            " Current loss 14744.58987359174\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 10790.81730437068\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 9856.452682389088\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 8894.64893317071\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 11301.86631256889\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 12258.397888687698\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 8880.96509289513\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 12765.555711076036\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 14183.916172488154\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 7894.361835579476\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 11284.819126858507\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 9335.140593826767\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 9344.835135169129\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 9820.854674591228\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 10843.519509283526\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 7879.836113175221\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 9831.564155249598\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 13255.667189304088\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 9321.615971758865\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 9340.330752385285\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 9767.58040475746\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 11852.860474104376\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 13748.798731392893\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 11789.622088263563\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 11334.746835743685\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 12290.764748412137\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 11796.663572875404\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 12293.560308765176\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 14670.35401045329\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 8331.780484505982\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 11308.976572740727\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 8347.406663349135\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 10246.78828876493\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 10788.786728082127\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 9868.996305608875\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 8395.910350944305\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 11697.221611176417\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 9342.578060807664\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 10815.797186117703\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 10774.833430607174\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 10813.651472760672\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 10820.371547540937\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 11249.163426537476\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 11741.08319561608\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 13290.291070472373\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 7376.809085277493\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 8893.708886993853\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 14259.777628960219\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 11274.135130856204\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 12753.736050335567\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 7366.322518841706\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 11807.891101649482\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 9843.699557509164\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 10388.637978571354\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 11316.218063336917\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 5414.663297350212\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 9849.6921731834\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 8839.293559119835\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 10337.639504753295\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 10284.430192181291\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 7398.59153510465\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 12295.886082561447\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 9364.110763469269\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 12266.202497677074\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 6347.052396764787\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 8356.512886274622\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 13744.16496252875\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 10770.68428147586\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 10817.834227526011\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 9817.666676990613\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 10839.897994214336\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 7872.779235644208\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 9374.651632829096\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 10376.343598408253\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 12783.177101955494\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 7872.628452936382\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 12783.858287481227\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 6907.254831066016\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 11308.67317740328\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 12272.236887202389\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 10259.730917541525\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 10821.434482859731\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 10307.322460295192\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 12261.383716486296\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 9854.269730472255\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 9745.28544254788\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 11735.730830584002\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 11298.073965951393\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 9842.451424224582\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 7325.158280346925\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 9794.354088196571\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 8822.872937842489\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 7863.804381220916\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 7877.189603385699\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 8311.451453695057\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 9348.956235694372\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 8849.257985893486\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 7909.3583007260195\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 10304.596918118563\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 9818.275033562748\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 10327.69609159567\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 7374.538683482771\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 12280.02427168594\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 9300.329839112645\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 8877.629289416378\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 9883.285397953041\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 13245.902567424873\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 8824.098960922027\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 6405.250029615572\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 8842.22677088173\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 10318.319491656159\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 11301.849474251954\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 10793.61925305022\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 9812.291594886312\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 11815.629655417826\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 10775.292236917085\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 9829.371164986642\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 8819.14438896287\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 8874.736866669618\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 11810.485143690461\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 8344.550062921806\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 9360.800365300467\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 10317.423602589348\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 13774.848548818158\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 10819.51898093558\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 8856.941306429395\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 10287.23831135085\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 12321.499385545543\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 11278.585486867962\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 7802.637554457088\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 10791.930479816452\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 12272.649779771073\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 8846.24800308773\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 8370.690949940898\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 12273.679260781733\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 9303.463629363301\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 10344.253644597578\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 8854.604923393812\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 11802.039225328208\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 9293.43385392617\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 11262.90259139269\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 10848.574645514454\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 14302.87017663774\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 10302.217756824373\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 5895.972018681065\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 9311.675377544661\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 10835.24544886723\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 9813.388834731022\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 12250.512552841845\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 8360.12066553026\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 8358.69319394286\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 12713.712275677284\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 13254.950829965037\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 10385.40595958296\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 9327.573302357077\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 7368.760329838348\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 2473.6515377751557\n",
            "\n",
            "Epoch： 23  start.\n",
            "Iteration number 0\n",
            " Current loss 7398.747520650502\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 10800.69465576304\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 8877.085114272919\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 8411.848560515662\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 9334.625923037142\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 11773.717468947296\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 9861.35669446157\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 10768.587283156074\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 7867.344946403681\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 7379.80001463175\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 9356.609388917363\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 11772.954980954522\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 9795.251479631861\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 11799.679731793574\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 7873.7593138748\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 9308.725354074115\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 11298.222521114549\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 13208.840253422275\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 7827.07026306849\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 9347.908907430183\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 8864.294427666464\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 10777.911765446286\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 12784.825955111228\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 8816.989727852593\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 8829.208677957475\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 8365.220298979115\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 10341.628489936793\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 9308.333068518805\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 7349.32716504616\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 10295.966628321828\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 8854.996584767263\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 7850.662265230646\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 11770.47055627721\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 13295.273422058697\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 8290.135965150543\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 11324.427069319176\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 9349.577905084865\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 12775.127273024294\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 12276.244950360026\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 7857.381245153945\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 9313.218097491153\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 10753.915884779855\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 11824.588647718916\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 9306.53881700696\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 12233.346078608236\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 6936.842084114826\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 8866.294025367131\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 12280.459723883861\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 11331.50907234185\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 8346.435190141794\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 12292.999816483945\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 9850.211332778932\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 10822.861923448067\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 8352.931676151762\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 11282.630602826346\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 10327.026010482774\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 11330.560874593719\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 10781.137136886971\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 10331.612406868138\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 11795.5826008722\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 10326.565640573514\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 8790.351545557707\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 11788.167588442337\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 9375.610904532754\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 13259.128157660667\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 10818.512719075756\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 12282.549441345138\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 7870.100495308779\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 8846.544983794292\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 10314.45036185607\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 7386.250924950124\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 9339.270315548623\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 11324.145139047467\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 13267.710044589867\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 11298.421977836146\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 6874.684360067926\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 7911.0678903632615\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 8837.540776478667\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 10279.516669123474\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 9821.486243217154\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 8342.324037292934\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 13270.392663247916\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 12749.423461667846\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 8858.489989706637\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 11303.756880095205\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 9799.868876338478\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 10826.056607496994\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 13761.978010892688\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 11327.662394872063\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 11785.867252824566\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 6895.493818916879\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 11739.934099491375\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 9806.639543433559\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 10820.869585302888\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 10774.255377888281\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 7840.822250991308\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 7883.927677132921\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 10325.283875302193\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 9307.323023675832\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 11301.489888575667\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 7408.531618449954\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 12799.868257026343\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 8376.345319049637\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 10328.308721260315\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 13265.137217884336\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 8831.976842145868\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 9352.382039363294\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 12754.944889724018\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 9348.666804214467\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 9826.808621044464\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 9354.35604506294\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 10357.339349209597\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 11804.035787807865\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 9363.409870663567\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 10326.34136221426\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 12252.07972985329\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 8361.635707757006\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 12272.008098126058\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 12765.832678501365\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 12252.077314383318\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 10315.228268708152\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 11340.436538992455\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 13270.847868657034\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 6380.65465252275\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 8886.70559694916\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 8818.645090234706\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 15215.547749226102\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 11278.613135294981\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 10805.166161719711\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 10336.417061098506\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 10326.601395857188\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 12786.139683965313\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 7890.6925739417\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 9788.889517437747\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 13262.338099669967\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 10784.761464657973\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 10298.651465682578\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 7840.154158251129\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 10801.321639753249\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 9827.324592596824\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 10328.449674822594\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 9348.123392665304\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 11237.512723951262\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 12731.688117444533\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 10766.809270232974\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 11807.178718685625\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 10822.23154895975\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 8802.714830809377\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 7367.607782030938\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 9401.2590907823\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 9342.091542865153\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 13242.477703342764\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 11822.442380083452\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 10773.194712440505\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 11264.089054156579\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 12799.459519731507\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 2958.8286028792745\n",
            "\n",
            "Epoch： 24  start.\n",
            "Iteration number 0\n",
            " Current loss 11304.367266012563\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 11308.720219409372\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 10769.615311650345\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 10289.673797727883\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 9282.996966069415\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 10323.936203757914\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 9392.824873824726\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 8397.532797622434\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 14711.57903345229\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 7384.2374624824715\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 8356.975820529133\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 10322.071237845628\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 8306.31536862807\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 10779.38153570918\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 10360.786807572542\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 9312.153331073167\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 10831.390325447515\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 13774.740693618896\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 9821.637913638966\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 7385.457083512079\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 10821.30305864572\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 9834.139655762569\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 7865.868038191461\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 10722.532655770225\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 9822.195545466795\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 12762.461121996748\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 15232.85511079146\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 12277.9067756031\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 7840.143049013958\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 12696.580072488236\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 12843.82862464555\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 10804.07119968385\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 9848.243732025125\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 8348.249272916004\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 9785.367943256491\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 12784.433391447064\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 10276.016132701558\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 12292.02466162325\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 10282.02390658378\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 10326.145861098074\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 11744.595412126546\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 12782.148599952776\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 11280.131162557303\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 8353.735230239512\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 16177.130107141957\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 8855.484203236501\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 7836.779167197498\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 11263.174894450372\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 6412.468608608591\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 11238.922642310696\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 9853.329537099682\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 12251.43366562024\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 8852.154145376031\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 6894.100834483984\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 10796.536104647765\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 5881.390147934835\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 11298.578045186992\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 11264.478421857415\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 11282.287055389043\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 10331.188459181303\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 10300.101829242783\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 11801.319739397724\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 9849.323356067955\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 11772.629060377905\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 8310.817647708489\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 10366.303364094752\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 10368.08027613832\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 11780.971034329874\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 9800.951612517232\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 8841.305328616383\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 9317.541893605372\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 7384.155465800763\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 9872.278962354188\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 7855.807088667309\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 7861.890013567551\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 8381.027535231935\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 8384.502329236433\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 11788.969674560765\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 9334.299821274693\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 11742.858735377717\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 7377.53490703555\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 12247.653974734561\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 13736.592745445061\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 9808.280263713526\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 11847.025772815407\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 12739.64619987501\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 10298.45767498504\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 11331.120992983393\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 11318.477613998268\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 12764.120868180082\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 9840.886852018031\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 11819.465091433472\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 10316.208223737201\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 10800.005633996007\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 14234.682116350905\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 10799.013030290507\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 8347.277717767258\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 8360.708651550001\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 11288.537520093523\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 8856.481337211297\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 19522.568488099325\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 9809.833625565283\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 8377.881063618574\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 9834.668228426008\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 7885.347977570591\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 8837.690145441256\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 12262.761040547712\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 9789.109253295412\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 7365.484426891691\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 12740.321192924064\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 9346.554986530442\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 9365.515516633739\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 9837.307139329667\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 9823.176666539988\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 11746.789140239245\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 5943.51385235488\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 4930.737336519207\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 8843.757379913526\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 11278.435781059232\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 11377.851162857656\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 5875.98693453678\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 10302.61832102954\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 9830.871170671187\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 7393.976362341211\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 10795.323790171176\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 11263.425615353546\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 9388.57715066745\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 9379.100015178929\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 10780.202938205022\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 12767.793557172485\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 13710.19013366844\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 9863.878520534163\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 11291.30480619731\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 11800.197545393989\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 9826.585490187797\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 11762.848391302094\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 13265.73656873629\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 8856.054901960899\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 10846.118666406786\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 10297.377151558092\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 9830.217134528613\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 10792.222059660016\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 11269.602199325465\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 10319.223747430713\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 8361.767091997735\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 7850.623951912605\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 11328.503007125588\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 9344.754253881332\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 10830.277495243543\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 12775.812077752198\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 8367.730202643917\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 9856.14869687217\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 8362.029129901759\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 8842.59272545163\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 11727.266229574438\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 8872.5148494344\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 1981.3295219055572\n",
            "\n",
            "Epoch： 25  start.\n",
            "Iteration number 0\n",
            " Current loss 12271.923694960286\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 8847.11737195724\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 14744.430502440486\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 9343.864451347297\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 7827.63623954578\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 6399.452113044518\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 8344.93240192532\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 11762.275318536724\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 7847.04698169573\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 7353.906003283587\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 9824.988024827722\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 11315.43835444459\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 7879.081026754431\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 12763.7887303872\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 9330.34868714332\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 11296.087165276596\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 10867.401915889146\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 7849.904359841494\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 10821.273538541504\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 10301.99546667711\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 8865.45336342937\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 8339.79604628951\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 7856.247864736622\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 12765.462855771453\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 13739.782788511951\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 12304.971553656034\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 12728.996562985521\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 10309.83723256093\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 12744.095726156644\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 8823.622746913454\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 12298.432422276386\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 10314.806518777788\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 13273.446697763518\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 10774.046042057154\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 12305.50154046798\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 9340.23782982504\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 11772.003094896634\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 10327.180040940593\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 10820.82026016379\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 11816.88372074036\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 9826.78983233111\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 8872.569007072067\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 10341.063208854608\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 8371.521624454745\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 9821.301033212116\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 10321.118681323085\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 8856.422510759538\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 11837.952979140977\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 9841.206917166073\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 12270.137055433062\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 9798.417828644053\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 10324.676223140077\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 9844.486951996003\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 11767.214019117426\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 9341.48497029689\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 14256.263721457308\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 6381.344643569666\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 7898.56160246035\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 9360.978317154508\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 13723.547044428473\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 7359.066315105412\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 9804.761896706852\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 10330.568224823917\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 11744.095354187679\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 9814.741753609047\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 13754.628890161232\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 10826.048849916417\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 10830.242635786204\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 6388.305514108246\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 9805.99643753683\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 9845.718470384752\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 11208.466381694841\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 10343.826917992912\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 10282.900965039711\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 11766.15332481472\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 7830.641736977652\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 7889.404905812836\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 8851.572709521537\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 10841.872933963698\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 8869.227002943324\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 11332.738874027084\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 10843.831370639902\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 7840.696934686419\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 12329.091360158453\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 9339.289700894871\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 15138.57578520966\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 10757.31129734114\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 9813.979389267717\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 10324.967619216557\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 9351.504031563574\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 10349.428506629909\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 9822.08013369272\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 14238.170569560785\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 8335.142095458432\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 10367.985794694006\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 11275.585690446365\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 9809.411415432698\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 10347.338475932713\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 10812.622611641134\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 6891.5455363924975\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 10808.718785306593\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 12751.716451543693\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 11278.333497416344\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 9773.217041020134\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 9841.62779131191\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 8302.09134312005\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 12783.476435250577\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 12785.398996060725\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 12824.717643414784\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 8331.199616041104\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 10303.789852585944\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 10289.479319433747\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 12758.33832866055\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 10801.376673536655\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 10779.079051096884\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 9336.271307328192\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 11277.93089004776\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 11777.20496944622\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 10815.990493909281\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 11286.967559358756\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 9833.056499464466\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 10767.97073818715\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 11306.79282235013\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 6431.449060651576\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 7848.843479553553\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 13755.236949872375\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 9339.820536167035\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 10318.142528284994\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 9299.122404978061\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 9805.279791085028\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 8876.118844302566\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 11797.625843744298\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 10300.306695090654\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 7906.084416201516\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 8329.99509577842\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 7833.492795208111\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 8356.552186416997\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 11819.781844432033\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 9336.720310258208\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 7370.909000240108\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 11826.540572770284\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 12756.233988555847\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 9340.103346111822\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 10391.286016427894\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 7399.434959761118\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 8357.601688038289\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 8902.489707060144\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 14643.58738447972\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 7838.454405101755\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 11319.07772857416\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 10831.698315647307\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 10808.020442591958\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 8327.422349945366\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 10295.740671604315\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 10279.804782391268\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 12277.075384346012\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 2482.8234090397236\n",
            "\n",
            "Epoch： 26  start.\n",
            "Iteration number 0\n",
            " Current loss 10292.255013664915\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 8867.059190003658\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 9299.837489017309\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 9293.83706001906\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 14218.286483197222\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 9824.124375915973\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 12799.853799832334\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 10754.845848718625\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 8380.370988579409\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 14685.764492454064\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 9847.280751677654\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 10359.521381412229\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 12751.245234310229\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 7859.4823055445895\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 12760.44897900835\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 14687.919524808985\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 8368.0505313831\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 9813.816690067386\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 8366.27758742317\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 11305.785280315842\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 13731.831609214008\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 8854.859205417219\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 7403.272192733812\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 9784.2977189754\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 10807.73125715422\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 10342.447331770549\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 11770.988975250657\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 5911.465376508175\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 10841.077724794632\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 12254.563475677201\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 8845.381381651863\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 8318.47844188265\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 8373.585632036222\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 9822.004202831455\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 9826.738025527915\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 9830.713772801148\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 11776.800513799455\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 10310.471559861213\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 8843.671491852177\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 13261.374512745797\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 8306.235164208043\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 9826.089946614407\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 9835.053358423089\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 9375.122580788175\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 10750.455155637843\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 8380.513788284794\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 7367.078918331691\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 9849.232417234236\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 9835.421189611396\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 10844.576933237719\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 9837.475483706814\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 12283.945714988295\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 10321.73159602303\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 7377.810570860815\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 12345.267691927422\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 10809.415725389463\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 6875.693764854152\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 7383.995134811752\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 9799.596656853213\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 11778.200875144801\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 8382.699820141239\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 7392.70970806012\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 10759.619761114309\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 6924.559168811658\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 9831.522750738244\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 12799.787656715223\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 9869.112027930594\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 11783.609876540724\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 11804.54520360476\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 8380.32557200096\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 9839.55516449734\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 10323.790261841941\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 13325.305017332757\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 8352.312044920807\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 9800.62812866666\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 7410.58622709426\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 10817.123481518443\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 8303.914861064215\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 9808.166056495429\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 9359.94369000691\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 8348.540400079219\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 10285.718433805723\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 9314.502903114271\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 10307.544553535834\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 9825.508626557854\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 9876.148076201705\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 10739.800292370675\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 12266.14249417926\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 8850.570299177176\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 12771.147891909894\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 13277.4203860558\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 12814.621035594633\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 9862.175731414289\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 9308.614732933482\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 13247.233613712364\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 9766.208609794565\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 10827.848005530916\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 7821.294388583123\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 12720.668081327187\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 10812.03359203221\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 5891.528396998814\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 11804.826068036851\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 9335.946936841337\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 12288.04923232218\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 7832.678935519237\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 7899.670171588001\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 14243.414082374815\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 8350.517000678394\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 10340.083264210549\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 11332.583583911512\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 8312.88813047684\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 12742.050863909968\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 11787.092384124247\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 9329.921347864043\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 11755.69436444961\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 7383.048198654996\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 6905.663201501928\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 11775.587455022116\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 10274.780900131507\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 10856.489866762833\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 10840.53395759708\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 8364.445111875948\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 10279.46133514242\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 11327.519897073646\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 11298.728429205876\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 9344.318500550773\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 15246.711139717987\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 11794.215214080763\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 8834.397659168155\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 9339.354332537692\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 9333.63684830806\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 11279.967513235759\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 10337.41520973266\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 8823.033388454622\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 9343.470464290567\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 12297.992049333796\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 12794.774863754212\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 12802.00356927319\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 12259.036661243634\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 11794.036268448443\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 10786.424826922675\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 7387.080432809805\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 8333.636168828838\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 11334.656936276035\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 13279.57104820475\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 9325.615334651347\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 12777.404181994089\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 10329.701186709088\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 13258.55303184561\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 13217.632155958981\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 8833.73295456636\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 8829.274130749822\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 7890.3391851343285\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 11312.18235957961\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 10761.049190715648\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 10731.587232923273\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 3470.6800637413394\n",
            "\n",
            "Epoch： 27  start.\n",
            "Iteration number 0\n",
            " Current loss 7374.670326578622\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 11343.574321228454\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 10324.935242425272\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 10296.54078406528\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 11811.583909441115\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 13283.446274108393\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 13224.152145580707\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 8365.772854606797\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 13226.357004080415\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 11294.511115741327\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 10824.541416387709\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 11835.374436745115\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 10266.576988721712\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 12796.731608063152\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 8843.629446801624\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 7339.799077359274\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 8380.956102105676\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 8343.846591287114\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 9839.54085900125\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 8298.162830236004\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 7853.858960116171\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 11302.041878362656\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 8840.926687126233\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 13684.85448702289\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 11298.200543603121\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 11299.78524377582\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 8390.309491764994\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 9310.0857460394\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 10794.992248626173\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 8361.726892901663\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 9352.663069502929\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 8845.739240065992\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 10789.635930521812\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 10851.19756232258\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 10791.522835827123\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 7868.0649199216305\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 8361.03594072527\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 10298.25380930133\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 7848.4354753548305\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 9356.163383043793\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 11311.393694974633\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 12266.85823339533\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 11829.135265806352\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 10820.305315195847\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 14755.313283271505\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 10306.877116585307\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 8392.13899562331\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 12278.768778074205\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 9837.043672019467\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 10277.3394248381\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 8838.576416279975\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 12726.705683082359\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 9828.926476149256\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 7365.078239265841\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 11749.736746289922\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 12795.53036275996\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 9834.00820602744\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 8811.440078823254\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 8816.228320875804\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 10300.701580550189\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 13735.912069673188\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 11791.341877244638\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 10336.457145551556\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 7388.685620226795\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 13297.338953844244\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 11262.043702991825\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 12256.958860263894\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 8849.393859527345\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 11314.81872171204\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 10393.527837889884\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 10802.344670924345\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 10365.224342052938\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 7381.347049587121\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 10854.087738580447\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 12318.499875459336\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 12224.720103042955\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 10800.52180045837\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 10293.280371481262\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 9838.010786173942\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 8846.77785887138\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 10312.188735665597\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 11783.351687088078\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 9845.333219750019\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 12717.796822069175\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 10323.436728915833\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 9828.138468665173\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 7849.759001766738\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 10766.95594178778\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 9773.724936569513\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 8858.502705440205\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 9828.582669390606\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 9344.151525774489\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 10806.828500310903\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 10315.088464388615\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 9813.19611745597\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 12300.912145471328\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 9285.029042576103\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 11806.983930676346\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 5408.341483046452\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 9330.584895050783\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 11816.370049953903\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 4433.592317766266\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 12764.583580005059\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 11795.311474648755\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 10774.155662726473\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 8845.392591278862\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 9376.523272947583\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 12783.909508408113\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 8368.863202576511\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 12765.06334031629\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 10816.712956959676\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 12306.963020586358\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 10818.834935999661\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 11331.183260724574\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 10346.074003779822\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 10351.931579832666\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 10348.125634947492\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 10265.798760420417\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 11249.774044123325\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 8869.122170887997\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 10304.46470578614\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 9335.818947926477\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 10332.313880289716\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 11790.195305052195\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 13762.334299690838\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 13738.696769901671\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 11278.274601449482\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 10823.098918028321\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 6881.651732330492\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 8343.849017705463\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 13741.489589489414\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 8810.78885548146\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 9795.776356026325\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 9306.435348632844\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 10830.60304811092\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 12744.432505501427\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 10782.805007317296\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 7875.039001626462\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 8848.458032791283\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 12274.11494996419\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 9304.062930333152\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 9345.19567354452\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 10815.054298240513\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 10729.843406709982\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 8840.223812781369\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 8817.586206812693\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 10849.900696105233\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 8850.327548223757\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 5895.311016978813\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 9830.668551808492\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 8859.70490840591\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 7861.095403745835\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 7877.938579286863\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 10361.33948960427\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 11299.645014009144\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 11313.257042098043\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 3449.4331914101667\n",
            "\n",
            "Epoch： 28  start.\n",
            "Iteration number 0\n",
            " Current loss 9814.372538155994\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 7894.704512436266\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 13795.359144870034\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 12236.475147522988\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 11818.431772914853\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 10808.929741002634\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 10797.9878454059\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 7364.8734377322035\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 14782.372459320812\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 9384.091089717485\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 7871.664070428558\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 7378.888846991736\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 9308.068704859252\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 10295.59890479531\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 10777.72270896889\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 8359.502783867381\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 10833.398272498107\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 7853.4196709036605\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 7877.181585789528\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 11303.749095803396\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 10849.431440862318\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 9346.508401906085\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 11758.071401958638\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 9832.745397113782\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 12270.787115937412\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 11792.446483527916\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 8856.040372193049\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 12775.393873575858\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 11803.526781299515\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 7376.579087850365\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 6898.993234974405\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 9305.425391290657\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 10829.036375631016\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 10323.048383218658\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 13271.862185481163\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 10831.84403458744\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 10804.60963021234\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 11823.900658979961\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 10830.884508295218\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 10323.679553880844\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 7849.575270269058\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 8860.01538580714\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 8838.794669570549\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 11277.898556645758\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 8358.24489502776\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 9797.414924646771\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 7840.68211764255\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 11288.422072127269\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 8881.403275389905\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 12291.9549280375\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 9835.704993064392\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 8354.676266947139\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 9378.968377886822\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 9798.685632261746\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 11790.566351032416\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 10867.866898368788\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 11336.392927070163\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 9334.60156912294\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 12316.432190213769\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 7387.9119198239505\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 8801.491825004152\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 12284.600214224372\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 8853.977703489963\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 9320.044557906707\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 10814.971912411644\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 11858.801571372891\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 9320.174541863089\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 10328.65299617891\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 10295.786754330344\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 10350.979231680998\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 8829.24183028105\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 7355.430864849253\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 10846.761389211868\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 10781.31169970786\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 9346.827110839651\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 11298.031483725568\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 10265.766700473772\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 10743.118024229274\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 9358.380675950217\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 8877.215303819225\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 8894.242709944643\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 10292.991203038266\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 13757.757763587335\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 13261.08428103834\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 8831.1377813795\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 6888.9458920619745\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 8389.407608635447\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 12269.74638063809\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 13230.320099924897\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 9869.29941876997\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 14225.86710756585\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 12278.372421043612\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 7838.56486794691\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 8817.634618739325\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 9861.184741641686\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 9817.429041668207\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 10342.058693415474\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 11756.172377986595\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 7358.6366028709435\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 9820.520059097453\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 11292.855302255917\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 11805.820127541545\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 11337.587725889793\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 9298.113948944705\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 12265.934863657953\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 12217.830070583903\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 15737.23413027584\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 12307.044967320471\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 9380.621466343313\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 13751.241183012582\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 7856.619253658968\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 10785.472591352527\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 10347.058305944985\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 9360.985487196562\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 12749.777674431738\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 8332.883418966816\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 7355.528508493927\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 15232.02867270997\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 8361.425513220736\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 12250.32037791863\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 10351.276173951295\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 12738.417526161149\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 8813.98460896577\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 9823.498864686371\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 11791.616939585045\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 9334.19351804193\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 11791.383064320918\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 10813.508428543117\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 5420.384887520052\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 10317.434293567941\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 13232.709510209923\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 13202.930759935674\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 11310.114061227543\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 10746.199444432086\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 9807.11833613836\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 11286.609709824703\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 8837.486415088033\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 9771.732394827448\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 10784.0514605313\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 7396.773987952325\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 12722.219568595536\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 8337.98236031596\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 9341.993589035716\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 6401.682524229087\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 9789.995670469702\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 11317.672131192227\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 8867.130271026861\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 10764.327401960862\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 12239.585396241835\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 7866.999143421823\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 13769.241458566645\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 12266.374951945221\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 9369.520278738119\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 11311.16676744465\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 8836.667414132395\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 6399.7631832329225\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 1972.6522313747375\n",
            "\n",
            "Epoch： 29  start.\n",
            "Iteration number 0\n",
            " Current loss 7336.080528285676\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 9809.932868134636\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 4944.563144686983\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 11807.201900215097\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 13706.86770743901\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 10788.395475831934\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 12284.451219574412\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 12777.742208569785\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 11308.414802211264\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 9822.321703092657\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 9342.387112095576\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 10293.011102090257\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 8813.22256700599\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 12765.39859974184\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 10361.252414897233\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 10772.701850137611\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 9824.420259980338\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 10317.194386217974\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 10315.689730640897\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 11726.344916377893\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 11335.962498390083\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 7366.144698689621\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 11298.391691449744\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 7850.692288729766\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 7368.922949631065\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 9362.91983280631\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 9824.89049509371\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 6921.351396525489\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 10789.505237390942\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 9359.893284045991\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 11826.811256165818\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 7379.12487847586\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 11821.449331499374\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 10299.181682355953\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 8337.52052795767\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 12745.729920351554\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 7377.095402714815\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 12777.754349329805\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 9844.447085850139\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 8883.026185370529\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 11336.587772506726\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 6880.412024048961\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 12712.13300705975\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 7896.905158969982\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 9341.289438554235\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 11778.176109154701\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 9815.13499845979\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 11722.28942168035\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 12307.125454497698\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 12281.166728432823\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 12787.883730399204\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 14279.22815209472\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 8889.505944645494\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 9819.29666718796\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 8839.672410851468\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 7847.364896993126\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 9363.237020295704\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 9345.983371238457\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 11794.657957252533\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 10309.230384321976\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 8850.65114644543\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 11287.446233376353\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 6910.106648377514\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 7815.759307849753\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 12241.044104219882\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 10326.025808448005\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 8834.549894597094\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 7827.100965263961\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 12298.101220073408\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 8851.62807031031\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 10806.787324915473\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 8824.682980456986\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 8846.616452526861\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 10326.898550272492\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 7886.655238771116\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 10791.844983489213\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 11773.172162892683\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 9295.667282236238\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 10737.528705297033\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 10823.153086292237\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 11794.240642919014\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 8344.437955074432\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 6412.749468355852\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 10339.101988886789\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 11311.226036627135\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 9852.555318673592\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 7804.1386946029525\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 10806.116293896004\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 10824.102382037454\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 8852.085637489643\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 10779.589544880859\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 10806.316398132194\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 11796.802325535135\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 12313.252676049848\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 11306.237641113155\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 11816.414073057804\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 10308.726256564947\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 9804.410637889796\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 7393.085335878706\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 13273.603670133045\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 10330.766257454288\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 7325.369956385684\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 8838.30565596573\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 9859.015736009898\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 12766.492675068941\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 10325.206971545162\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 9335.893590643895\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 12277.310689144706\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 10333.057098384395\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 12290.374657627137\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 8347.251007796027\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 9833.270476718832\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 14664.485875905639\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 11295.496575370587\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 10744.07052796349\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 12735.137662865616\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 7879.651433728959\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 10798.584334737738\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 7372.002409607887\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 8364.851484655825\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 10353.426848082072\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 10856.675087266744\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 9340.258439068364\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 10318.635962571641\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 11797.931955278205\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 7876.78979176264\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 10844.549288794784\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 10345.224059613003\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 11800.15361045723\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 7876.55628207978\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 9340.789397253495\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 10841.396587972624\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 7388.286325024275\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 11262.200620793403\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 13781.518042117137\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 9800.98883907939\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 12251.242531698988\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 10866.486210923482\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 11285.396675468757\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 13729.60446443542\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 10838.85376942834\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 9849.571015573107\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 10820.41576920206\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 8792.062282942796\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 12741.06426338393\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 12697.158596332076\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 7377.75074586793\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 10301.841021749693\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 10790.68732080612\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 14159.148424696263\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 8396.148434634044\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 11326.99823169113\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 13259.800622365356\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 12280.850688111042\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 10302.737683177498\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 8854.792048657784\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 3963.4593875285273\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS6HAxUA0YqG"
      },
      "source": [
        "### **Building a Classification Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsH4H72rr8-x"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_features=4, out_features=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=128,\n",
        "                             out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, \n",
        "                             out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84,  \n",
        "                             out_features=2)\n",
        "        self.activation = nn.Softmax(dim=1)\n",
        "\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = F.relu(self.fc3(X))\n",
        "        return self.activation(X)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YsDUg3tVM1Qo",
        "outputId": "cb3cb974-edf6-4b8c-fabf-daeb2acd0564"
      },
      "source": [
        "net2 = NeuralNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "counter = []\n",
        "loss_history = [] \n",
        "iteration_number= 0\n",
        "\n",
        "for epoch in range(0,NUMBER_EPOCHS):\n",
        "    print(\"Epoch：\", epoch, \" start.\")\n",
        "    for i, data in enumerate(trainloader,0):\n",
        "        img0, img1 , labels, class_labels = data \n",
        "        img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()#move to GPU\n",
        "        optimizer.zero_grad()#clear the calculated grad in previous batch\n",
        "        outputs = net([img0,img1])\n",
        "        out2 = net2(outputs[0])\n",
        "        loss = criterion(out2, class_labels[0].cuda())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"Iteration number {}\\n Current loss {}\\n\".format(i,loss.item()))\n",
        "        if i %10 == 0 :#show changes of loss value after each 10 batches\n",
        "            iteration_number +=10\n",
        "            counter.append(iteration_number)\n",
        "            loss_history.append(loss.item())\n",
        "\n",
        "        torch.save(net2.state_dict(),\"/content/drive/My Drive/saved_models/resnet-clf.pth\")\n",
        "    \n",
        "    #test the network after finish each epoch, to have a brief training result.\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():#essential for testing\n",
        "        for data in valloader:\n",
        "            img0, img1 , labels, class_labels = data\n",
        "            img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()\n",
        "            outputs = net([img0,img1])\n",
        "            out = net2(outputs[0])\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            total_val += class_labels[0].cuda().size(0)\n",
        "            correct_val += (predicted == class_labels[0].cuda()).sum().item()\n",
        "            \n",
        "    print('Accuracy of the network on the', total_val,': %d %%' % (100 * correct_val / total_val))\n",
        "    show_plot(counter,loss_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch： 0  start.\n",
            "Iteration number 0\n",
            " Current loss 0.694160521030426\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 0.6935561299324036\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 0.6935670971870422\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 0.6939022541046143\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 0.6941693425178528\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 0.6939532160758972\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 0.694049596786499\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 0.693726658821106\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 0.6940855979919434\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 0.6936243772506714\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 0.6929059624671936\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 0.693048357963562\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 0.6930776238441467\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 0.6930447220802307\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 0.6927691698074341\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 0.6928892731666565\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 0.6929106712341309\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 0.6934037804603577\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 0.6935398578643799\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 0.6934861540794373\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 0.6918866038322449\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 0.6929201483726501\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 0.6926009058952332\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 0.6936221718788147\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 0.6931816339492798\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 0.6926413178443909\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 0.6936144828796387\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 0.6922044157981873\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 0.693120539188385\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 0.6922380328178406\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 0.6931137442588806\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 0.6924365758895874\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 0.6928316950798035\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 0.6925095319747925\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 0.6917081475257874\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 0.6931875348091125\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 0.691973090171814\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 0.6920514106750488\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 0.6910825371742249\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 0.691890299320221\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 0.6918664574623108\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 0.6925193071365356\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 0.6911343932151794\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 0.6922165751457214\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 0.6914355754852295\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 0.6912723183631897\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 0.6903553009033203\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 0.6915373802185059\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 0.6905387043952942\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 0.6906171441078186\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 0.6917493343353271\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 0.6923316121101379\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 0.6923816204071045\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 0.6904252171516418\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 0.6911570429801941\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 0.6917110085487366\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 0.6908217072486877\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 0.6901798844337463\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 0.6905611753463745\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 0.690498948097229\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 0.6896676421165466\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 0.6913960576057434\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 0.6886208653450012\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 0.6898879408836365\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 0.6897475123405457\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 0.6904635429382324\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 0.6904966235160828\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 0.6896364092826843\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 0.6892109513282776\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 0.6904183030128479\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 0.6901407241821289\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 0.6884616017341614\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 0.69148188829422\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 0.688564121723175\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 0.6910412907600403\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 0.6908738017082214\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 0.6903216242790222\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 0.6888436675071716\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 0.6897768378257751\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 0.6894779801368713\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 0.6891409158706665\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 0.6913398504257202\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 0.6889660954475403\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 0.6897062063217163\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 0.6880854964256287\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 0.6882663369178772\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 0.6889334917068481\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 0.687800943851471\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 0.6888124942779541\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 0.6887324452400208\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 0.6886643767356873\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 0.6872919797897339\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 0.6891465783119202\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 0.6906827688217163\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 0.687625527381897\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 0.687991738319397\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 0.6870427131652832\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 0.6879709959030151\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 0.6892617344856262\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 0.6901220083236694\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 0.6865480542182922\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 0.6876032948493958\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 0.6872079968452454\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 0.6889619827270508\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 0.6894567012786865\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 0.688529372215271\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 0.689015805721283\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 0.6852980852127075\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 0.6893362998962402\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 0.6852723956108093\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 0.6888244152069092\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 0.6878618597984314\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 0.6854087710380554\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 0.6864985227584839\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 0.6873888969421387\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 0.6867864727973938\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 0.6876844763755798\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 0.6858441829681396\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 0.686800479888916\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 0.6884698867797852\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 0.6879644989967346\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 0.683242678642273\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 0.6849984526634216\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 0.6854380965232849\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 0.6874565482139587\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 0.6861742734909058\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 0.6859185695648193\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 0.6851453185081482\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 0.6821195483207703\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 0.6845165491104126\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 0.6850259900093079\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 0.6879242658615112\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 0.6829798221588135\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 0.6868415474891663\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 0.6846065521240234\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 0.685707688331604\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 0.6877340078353882\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 0.6890166401863098\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 0.6811786890029907\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 0.6863361597061157\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 0.683922290802002\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 0.6900935173034668\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 0.6846612095832825\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 0.6821190714836121\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 0.690623939037323\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 0.6878494620323181\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 0.6829418540000916\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 0.6830191016197205\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 0.6864679455757141\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 0.685560941696167\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 0.6827293038368225\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 0.6860941648483276\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 0.6847016215324402\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 0.6899486184120178\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 0.6846626400947571\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 0.6859952211380005\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 0.6914736032485962\n",
            "\n",
            "Accuracy of the network on the 10000 : 70 %\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch： 1  start.\n",
            "Iteration number 0\n",
            " Current loss 0.6863218545913696\n",
            "\n",
            "Iteration number 1\n",
            " Current loss 0.6828216314315796\n",
            "\n",
            "Iteration number 2\n",
            " Current loss 0.6848461031913757\n",
            "\n",
            "Iteration number 3\n",
            " Current loss 0.6824364066123962\n",
            "\n",
            "Iteration number 4\n",
            " Current loss 0.6814417243003845\n",
            "\n",
            "Iteration number 5\n",
            " Current loss 0.6828042268753052\n",
            "\n",
            "Iteration number 6\n",
            " Current loss 0.6872509717941284\n",
            "\n",
            "Iteration number 7\n",
            " Current loss 0.6877359747886658\n",
            "\n",
            "Iteration number 8\n",
            " Current loss 0.6833492517471313\n",
            "\n",
            "Iteration number 9\n",
            " Current loss 0.6825242638587952\n",
            "\n",
            "Iteration number 10\n",
            " Current loss 0.6866552233695984\n",
            "\n",
            "Iteration number 11\n",
            " Current loss 0.6839876770973206\n",
            "\n",
            "Iteration number 12\n",
            " Current loss 0.6856096982955933\n",
            "\n",
            "Iteration number 13\n",
            " Current loss 0.6899235248565674\n",
            "\n",
            "Iteration number 14\n",
            " Current loss 0.6870578527450562\n",
            "\n",
            "Iteration number 15\n",
            " Current loss 0.6852130889892578\n",
            "\n",
            "Iteration number 16\n",
            " Current loss 0.6832790374755859\n",
            "\n",
            "Iteration number 17\n",
            " Current loss 0.6821337342262268\n",
            "\n",
            "Iteration number 18\n",
            " Current loss 0.6870435476303101\n",
            "\n",
            "Iteration number 19\n",
            " Current loss 0.6831580400466919\n",
            "\n",
            "Iteration number 20\n",
            " Current loss 0.6822507977485657\n",
            "\n",
            "Iteration number 21\n",
            " Current loss 0.6872856020927429\n",
            "\n",
            "Iteration number 22\n",
            " Current loss 0.6801477670669556\n",
            "\n",
            "Iteration number 23\n",
            " Current loss 0.685969352722168\n",
            "\n",
            "Iteration number 24\n",
            " Current loss 0.6876770853996277\n",
            "\n",
            "Iteration number 25\n",
            " Current loss 0.684992253780365\n",
            "\n",
            "Iteration number 26\n",
            " Current loss 0.681175947189331\n",
            "\n",
            "Iteration number 27\n",
            " Current loss 0.6870296597480774\n",
            "\n",
            "Iteration number 28\n",
            " Current loss 0.6815158724784851\n",
            "\n",
            "Iteration number 29\n",
            " Current loss 0.6809074282646179\n",
            "\n",
            "Iteration number 30\n",
            " Current loss 0.6838697195053101\n",
            "\n",
            "Iteration number 31\n",
            " Current loss 0.680799663066864\n",
            "\n",
            "Iteration number 32\n",
            " Current loss 0.6795998215675354\n",
            "\n",
            "Iteration number 33\n",
            " Current loss 0.6915255784988403\n",
            "\n",
            "Iteration number 34\n",
            " Current loss 0.6758691072463989\n",
            "\n",
            "Iteration number 35\n",
            " Current loss 0.6811628341674805\n",
            "\n",
            "Iteration number 36\n",
            " Current loss 0.680729329586029\n",
            "\n",
            "Iteration number 37\n",
            " Current loss 0.6864898204803467\n",
            "\n",
            "Iteration number 38\n",
            " Current loss 0.6829987168312073\n",
            "\n",
            "Iteration number 39\n",
            " Current loss 0.6829574704170227\n",
            "\n",
            "Iteration number 40\n",
            " Current loss 0.6810034513473511\n",
            "\n",
            "Iteration number 41\n",
            " Current loss 0.6838935017585754\n",
            "\n",
            "Iteration number 42\n",
            " Current loss 0.6827706098556519\n",
            "\n",
            "Iteration number 43\n",
            " Current loss 0.682711124420166\n",
            "\n",
            "Iteration number 44\n",
            " Current loss 0.6875648498535156\n",
            "\n",
            "Iteration number 45\n",
            " Current loss 0.6849518418312073\n",
            "\n",
            "Iteration number 46\n",
            " Current loss 0.6836156845092773\n",
            "\n",
            "Iteration number 47\n",
            " Current loss 0.6812595725059509\n",
            "\n",
            "Iteration number 48\n",
            " Current loss 0.6780887246131897\n",
            "\n",
            "Iteration number 49\n",
            " Current loss 0.6797890067100525\n",
            "\n",
            "Iteration number 50\n",
            " Current loss 0.6806907653808594\n",
            "\n",
            "Iteration number 51\n",
            " Current loss 0.6796501278877258\n",
            "\n",
            "Iteration number 52\n",
            " Current loss 0.6792153120040894\n",
            "\n",
            "Iteration number 53\n",
            " Current loss 0.6902538537979126\n",
            "\n",
            "Iteration number 54\n",
            " Current loss 0.6810428500175476\n",
            "\n",
            "Iteration number 55\n",
            " Current loss 0.6779430508613586\n",
            "\n",
            "Iteration number 56\n",
            " Current loss 0.6839330792427063\n",
            "\n",
            "Iteration number 57\n",
            " Current loss 0.6852632761001587\n",
            "\n",
            "Iteration number 58\n",
            " Current loss 0.6824179291725159\n",
            "\n",
            "Iteration number 59\n",
            " Current loss 0.6798793077468872\n",
            "\n",
            "Iteration number 60\n",
            " Current loss 0.680477499961853\n",
            "\n",
            "Iteration number 61\n",
            " Current loss 0.6844671368598938\n",
            "\n",
            "Iteration number 62\n",
            " Current loss 0.6864764094352722\n",
            "\n",
            "Iteration number 63\n",
            " Current loss 0.6810428500175476\n",
            "\n",
            "Iteration number 64\n",
            " Current loss 0.6785279512405396\n",
            "\n",
            "Iteration number 65\n",
            " Current loss 0.6765790581703186\n",
            "\n",
            "Iteration number 66\n",
            " Current loss 0.677787184715271\n",
            "\n",
            "Iteration number 67\n",
            " Current loss 0.6823199987411499\n",
            "\n",
            "Iteration number 68\n",
            " Current loss 0.6783215403556824\n",
            "\n",
            "Iteration number 69\n",
            " Current loss 0.679780125617981\n",
            "\n",
            "Iteration number 70\n",
            " Current loss 0.6824105381965637\n",
            "\n",
            "Iteration number 71\n",
            " Current loss 0.6792369484901428\n",
            "\n",
            "Iteration number 72\n",
            " Current loss 0.6824154853820801\n",
            "\n",
            "Iteration number 73\n",
            " Current loss 0.6850714087486267\n",
            "\n",
            "Iteration number 74\n",
            " Current loss 0.6781729459762573\n",
            "\n",
            "Iteration number 75\n",
            " Current loss 0.6780858635902405\n",
            "\n",
            "Iteration number 76\n",
            " Current loss 0.6802201271057129\n",
            "\n",
            "Iteration number 77\n",
            " Current loss 0.6794979572296143\n",
            "\n",
            "Iteration number 78\n",
            " Current loss 0.6769447326660156\n",
            "\n",
            "Iteration number 79\n",
            " Current loss 0.6823959350585938\n",
            "\n",
            "Iteration number 80\n",
            " Current loss 0.6754785776138306\n",
            "\n",
            "Iteration number 81\n",
            " Current loss 0.6824434399604797\n",
            "\n",
            "Iteration number 82\n",
            " Current loss 0.6817630529403687\n",
            "\n",
            "Iteration number 83\n",
            " Current loss 0.6782359480857849\n",
            "\n",
            "Iteration number 84\n",
            " Current loss 0.6827703714370728\n",
            "\n",
            "Iteration number 85\n",
            " Current loss 0.6825265884399414\n",
            "\n",
            "Iteration number 86\n",
            " Current loss 0.6786285042762756\n",
            "\n",
            "Iteration number 87\n",
            " Current loss 0.6772586703300476\n",
            "\n",
            "Iteration number 88\n",
            " Current loss 0.678348958492279\n",
            "\n",
            "Iteration number 89\n",
            " Current loss 0.6846988201141357\n",
            "\n",
            "Iteration number 90\n",
            " Current loss 0.6773532629013062\n",
            "\n",
            "Iteration number 91\n",
            " Current loss 0.6786953806877136\n",
            "\n",
            "Iteration number 92\n",
            " Current loss 0.6798244714736938\n",
            "\n",
            "Iteration number 93\n",
            " Current loss 0.6765533089637756\n",
            "\n",
            "Iteration number 94\n",
            " Current loss 0.6791538000106812\n",
            "\n",
            "Iteration number 95\n",
            " Current loss 0.6803784370422363\n",
            "\n",
            "Iteration number 96\n",
            " Current loss 0.675955593585968\n",
            "\n",
            "Iteration number 97\n",
            " Current loss 0.6774588823318481\n",
            "\n",
            "Iteration number 98\n",
            " Current loss 0.6783069968223572\n",
            "\n",
            "Iteration number 99\n",
            " Current loss 0.6751631498336792\n",
            "\n",
            "Iteration number 100\n",
            " Current loss 0.6785935759544373\n",
            "\n",
            "Iteration number 101\n",
            " Current loss 0.6781372427940369\n",
            "\n",
            "Iteration number 102\n",
            " Current loss 0.6753856539726257\n",
            "\n",
            "Iteration number 103\n",
            " Current loss 0.6759375333786011\n",
            "\n",
            "Iteration number 104\n",
            " Current loss 0.6789169907569885\n",
            "\n",
            "Iteration number 105\n",
            " Current loss 0.6751117706298828\n",
            "\n",
            "Iteration number 106\n",
            " Current loss 0.6843546032905579\n",
            "\n",
            "Iteration number 107\n",
            " Current loss 0.6866248846054077\n",
            "\n",
            "Iteration number 108\n",
            " Current loss 0.6767369508743286\n",
            "\n",
            "Iteration number 109\n",
            " Current loss 0.675040602684021\n",
            "\n",
            "Iteration number 110\n",
            " Current loss 0.6797739267349243\n",
            "\n",
            "Iteration number 111\n",
            " Current loss 0.6775233745574951\n",
            "\n",
            "Iteration number 112\n",
            " Current loss 0.6765459775924683\n",
            "\n",
            "Iteration number 113\n",
            " Current loss 0.6801583766937256\n",
            "\n",
            "Iteration number 114\n",
            " Current loss 0.6786845326423645\n",
            "\n",
            "Iteration number 115\n",
            " Current loss 0.6800593137741089\n",
            "\n",
            "Iteration number 116\n",
            " Current loss 0.680006742477417\n",
            "\n",
            "Iteration number 117\n",
            " Current loss 0.6701962947845459\n",
            "\n",
            "Iteration number 118\n",
            " Current loss 0.6775954365730286\n",
            "\n",
            "Iteration number 119\n",
            " Current loss 0.6793904900550842\n",
            "\n",
            "Iteration number 120\n",
            " Current loss 0.681200385093689\n",
            "\n",
            "Iteration number 121\n",
            " Current loss 0.6823374629020691\n",
            "\n",
            "Iteration number 122\n",
            " Current loss 0.672706127166748\n",
            "\n",
            "Iteration number 123\n",
            " Current loss 0.6698652505874634\n",
            "\n",
            "Iteration number 124\n",
            " Current loss 0.6744436025619507\n",
            "\n",
            "Iteration number 125\n",
            " Current loss 0.6772445440292358\n",
            "\n",
            "Iteration number 126\n",
            " Current loss 0.6816992163658142\n",
            "\n",
            "Iteration number 127\n",
            " Current loss 0.6793232560157776\n",
            "\n",
            "Iteration number 128\n",
            " Current loss 0.684185266494751\n",
            "\n",
            "Iteration number 129\n",
            " Current loss 0.6789236068725586\n",
            "\n",
            "Iteration number 130\n",
            " Current loss 0.6668689250946045\n",
            "\n",
            "Iteration number 131\n",
            " Current loss 0.6678321361541748\n",
            "\n",
            "Iteration number 132\n",
            " Current loss 0.678132951259613\n",
            "\n",
            "Iteration number 133\n",
            " Current loss 0.6745670437812805\n",
            "\n",
            "Iteration number 134\n",
            " Current loss 0.6712597012519836\n",
            "\n",
            "Iteration number 135\n",
            " Current loss 0.6761271953582764\n",
            "\n",
            "Iteration number 136\n",
            " Current loss 0.6736757755279541\n",
            "\n",
            "Iteration number 137\n",
            " Current loss 0.6741860508918762\n",
            "\n",
            "Iteration number 138\n",
            " Current loss 0.6765365600585938\n",
            "\n",
            "Iteration number 139\n",
            " Current loss 0.6734207272529602\n",
            "\n",
            "Iteration number 140\n",
            " Current loss 0.677491307258606\n",
            "\n",
            "Iteration number 141\n",
            " Current loss 0.6801732182502747\n",
            "\n",
            "Iteration number 142\n",
            " Current loss 0.6667935848236084\n",
            "\n",
            "Iteration number 143\n",
            " Current loss 0.6751288771629333\n",
            "\n",
            "Iteration number 144\n",
            " Current loss 0.6773461699485779\n",
            "\n",
            "Iteration number 145\n",
            " Current loss 0.6785508990287781\n",
            "\n",
            "Iteration number 146\n",
            " Current loss 0.6791374087333679\n",
            "\n",
            "Iteration number 147\n",
            " Current loss 0.66390460729599\n",
            "\n",
            "Iteration number 148\n",
            " Current loss 0.6765874028205872\n",
            "\n",
            "Iteration number 149\n",
            " Current loss 0.6754931807518005\n",
            "\n",
            "Iteration number 150\n",
            " Current loss 0.6751977801322937\n",
            "\n",
            "Iteration number 151\n",
            " Current loss 0.6678751707077026\n",
            "\n",
            "Iteration number 152\n",
            " Current loss 0.6733077764511108\n",
            "\n",
            "Iteration number 153\n",
            " Current loss 0.6675691604614258\n",
            "\n",
            "Iteration number 154\n",
            " Current loss 0.6750299334526062\n",
            "\n",
            "Iteration number 155\n",
            " Current loss 0.6714847683906555\n",
            "\n",
            "Iteration number 156\n",
            " Current loss 0.6967276334762573\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRbgGOBa0iTs"
      },
      "source": [
        "torch.save(net.state_dict(),\"/content/drive/My Drive/saved_models/resnet-cffn.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv4aOpOe19kW"
      },
      "source": [
        "### **Streamlit GUI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYaTnxv628FL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914c9c7d-b7ca-4931-c879-107e6ec28d57"
      },
      "source": [
        "#Writing all necessary functions in one cell\n",
        "%%writefile DeepFakeGUI.py\n",
        "import streamlit as st\n",
        "\n",
        "from itertools import permutations, product\n",
        "from random import sample, choice, shuffle\n",
        "from glob import glob\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps    \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used, and then connected by three fc layer.\n",
        "    def __init__(self,model,n):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn1 = model\n",
        "        self.fc1 = nn.Linear(n, 500)\n",
        "        self.fc2 = nn.Linear(500, 500)\n",
        "        self.fc3 = nn.Linear(500, 128)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):#did not know how to let two resnet share the same param.\n",
        "        results = []\n",
        "\n",
        "        for input in inputs:\n",
        "            output = self.cnn1(input)\n",
        "            output = output.view(output.size()[0], -1)\n",
        "            output = F.relu(self.fc1(output))\n",
        "            output = F.relu(self.fc2(output))\n",
        "            output = self.fc3(output)\n",
        "\n",
        "            results.append(output)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_features=4, out_features=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=128,\n",
        "                             out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, \n",
        "                             out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84,  \n",
        "                             out_features=2)\n",
        "        self.activation = nn.Softmax(dim=1)\n",
        "\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = F.relu(self.fc3(X))\n",
        "        return self.activation(X)\n",
        "\n",
        "\n",
        "st.title(\"Deepfake Detection App\")\n",
        "st.subheader(\"This app takes in an image uploaded by the user and upon clicking the 'Verdict' button, displays if the uploaded image is fake or real\" )\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image from your file directory\", type=[\"jpg\",\"png\",\"jpeg\"])\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "\n",
        "    net = SiameseNetwork(models.resnet50(pretrained=True),1000).cuda()\n",
        "    net2 = NeuralNet().cuda()\n",
        "\n",
        "    net.load_state_dict(torch.load(\"net.pth\"))\n",
        "    net2.load_state_dict(torch.load(\"net2.pth\"))\n",
        "\n",
        "    net.eval()\n",
        "    net2.eval()\n",
        "\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width= True)\n",
        "    st.write(\"\")\n",
        "    test_transforms = transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor()])\n",
        "    image_tensor = test_transforms(image).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input = Variable(image_tensor)\n",
        "    input = input.cuda()\n",
        "    out1=net([input])\n",
        "    output = net2(out1[0])\n",
        "    print(output.data.cpu().numpy())\n",
        "    prediction = output.data.cpu().numpy().argmax()\n",
        "\n",
        "    if(st.button('Verdict')):\n",
        "        if prediction == 0:\n",
        "            st.error(\"The image uploaded is fake\")\n",
        "        elif prediction == 1:\n",
        "            st.success(\"The image uploaded is real\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting DeepFakeGUI.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zUnCLSM3HKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6603be-05f6-4669-8162-54af5cbd9512"
      },
      "source": [
        "#Command to run the GUI\n",
        "!streamlit run DeepFakeGUI.py & npx localtunnel --port 8501"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.418s\n",
            "your url is: https://tender-turtle-63.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.234.14.117:8501\u001b[0m\n",
            "\u001b[0m\n",
            "[[0.5 0.5]]\n",
            "[[0.5 0.5]]\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}